{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# textsimilarity\n",
    "\n",
    "Examples of using the textsimilarity package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Get text similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['relaxing vacation',\n",
       " 'martini and chocolate',\n",
       " 'wedding party',\n",
       " 'bridal flowers',\n",
       " 'soccer game',\n",
       " 'skate park']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import os, sys\n",
    "\n",
    "#load example text corpus for comparison\n",
    "data_location = os.path.join(sys.path[0], 'data', 'comparison_corpus.csv')\n",
    "input_data = pd.read_csv(data_location)\n",
    "comparison_corpus = input_data['phrases_to_compare'].values.tolist()\n",
    "comparison_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from textsimilarity import text_models, rankers\n",
    "\n",
    "#load a text model to use for generating text embeddings\n",
    "bert_model = text_models.BertBaseModel()    \n",
    "\n",
    "#specify which model and corpus to use for comparison\n",
    "cosine_sim_ranker = rankers.CosineSimilarityRanker(\n",
    "                    bert_model, \n",
    "                    comparison_corpus\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\megan\\Documents\\Career\\MSDS\\DATA 515\\FinalProject\\examples\\examples.ipynb Cell 5'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/megan/Documents/Career/MSDS/DATA%20515/FinalProject/examples/examples.ipynb#ch0000004?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mCosine similarity score: \u001b[39m\u001b[39m'\u001b[39m, closest_phrase_cos_sim[\u001b[39m1\u001b[39m], \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m------\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/megan/Documents/Career/MSDS/DATA%20515/FinalProject/examples/examples.ipynb#ch0000004?line=6'>7</a>\u001b[0m \u001b[39m#print text phrases and cosine similarity scores\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/megan/Documents/Career/MSDS/DATA%20515/FinalProject/examples/examples.ipynb#ch0000004?line=7'>8</a>\u001b[0m print_closest_result(\u001b[39m'\u001b[39;49m\u001b[39mmassage\u001b[39;49m\u001b[39m'\u001b[39;49m, cosine_sim_ranker)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/megan/Documents/Career/MSDS/DATA%20515/FinalProject/examples/examples.ipynb#ch0000004?line=8'>9</a>\u001b[0m print_closest_result(\u001b[39m'\u001b[39m\u001b[39mfootball\u001b[39m\u001b[39m'\u001b[39m, cosine_sim_ranker)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/megan/Documents/Career/MSDS/DATA%20515/FinalProject/examples/examples.ipynb#ch0000004?line=9'>10</a>\u001b[0m print_closest_result(\u001b[39m'\u001b[39m\u001b[39mgirls night out\u001b[39m\u001b[39m'\u001b[39m, cosine_sim_ranker)\n",
      "\u001b[1;32mc:\\Users\\megan\\Documents\\Career\\MSDS\\DATA 515\\FinalProject\\examples\\examples.ipynb Cell 5'\u001b[0m in \u001b[0;36mprint_closest_result\u001b[1;34m(target, ranker)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/megan/Documents/Career/MSDS/DATA%20515/FinalProject/examples/examples.ipynb#ch0000004?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprint_closest_result\u001b[39m(target, ranker):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/megan/Documents/Career/MSDS/DATA%20515/FinalProject/examples/examples.ipynb#ch0000004?line=1'>2</a>\u001b[0m     closest_phrase_cos_sim \u001b[39m=\u001b[39m ranker\u001b[39m.\u001b[39;49mrank_on_similarity(target)[\u001b[39m0\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/megan/Documents/Career/MSDS/DATA%20515/FinalProject/examples/examples.ipynb#ch0000004?line=2'>3</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m------\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mTarget text phrase: \u001b[39m\u001b[39m'\u001b[39m, target)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/megan/Documents/Career/MSDS/DATA%20515/FinalProject/examples/examples.ipynb#ch0000004?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mMost similar text phrase from corpus: \u001b[39m\u001b[39m'\u001b[39m, closest_phrase_cos_sim[\u001b[39m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\users\\megan\\documents\\career\\msds\\data 515\\finalproject\\textsimilarity\\rankers.py:51\u001b[0m, in \u001b[0;36mCosineSimilarityRanker.rank_on_similarity\u001b[1;34m(self, target_text)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/users/megan/documents/career/msds/data%20515/finalproject/textsimilarity/rankers.py?line=48'>49</a>\u001b[0m cosine_sim_tracker \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='file:///c%3A/users/megan/documents/career/msds/data%20515/finalproject/textsimilarity/rankers.py?line=49'>50</a>\u001b[0m \u001b[39mfor\u001b[39;00m text, emb \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomparison_dict\u001b[39m.\u001b[39mitems():\n\u001b[1;32m---> <a href='file:///c%3A/users/megan/documents/career/msds/data%20515/finalproject/textsimilarity/rankers.py?line=50'>51</a>\u001b[0m     cosine_sim \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_calculate_cosine_similarity(target_emb, emb)\n\u001b[0;32m     <a href='file:///c%3A/users/megan/documents/career/msds/data%20515/finalproject/textsimilarity/rankers.py?line=51'>52</a>\u001b[0m     cosine_sim_tracker\u001b[39m.\u001b[39mappend((text, cosine_sim))\n\u001b[0;32m     <a href='file:///c%3A/users/megan/documents/career/msds/data%20515/finalproject/textsimilarity/rankers.py?line=52'>53</a>\u001b[0m ranked_similarity \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(cosine_sim_tracker, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m pair: pair[c\u001b[39m.\u001b[39mSECOND_IDX], reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\users\\megan\\documents\\career\\msds\\data 515\\finalproject\\textsimilarity\\rankers.py:39\u001b[0m, in \u001b[0;36mCosineSimilarityRanker._calculate_cosine_similarity\u001b[1;34m(self, emb0, emb1)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/users/megan/documents/career/msds/data%20515/finalproject/textsimilarity/rankers.py?line=36'>37</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_calculate_cosine_similarity\u001b[39m(\u001b[39mself\u001b[39m, emb0, emb1):\n\u001b[0;32m     <a href='file:///c%3A/users/megan/documents/career/msds/data%20515/finalproject/textsimilarity/rankers.py?line=37'>38</a>\u001b[0m     \u001b[39m\"\"\"Calculate and return cosine similarity.\"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/users/megan/documents/career/msds/data%20515/finalproject/textsimilarity/rankers.py?line=38'>39</a>\u001b[0m     numerator \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(emb0, emb1)\n\u001b[0;32m     <a href='file:///c%3A/users/megan/documents/career/msds/data%20515/finalproject/textsimilarity/rankers.py?line=39'>40</a>\u001b[0m     denominator \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(emb0)\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(emb1)\n\u001b[0;32m     <a href='file:///c%3A/users/megan/documents/career/msds/data%20515/finalproject/textsimilarity/rankers.py?line=40'>41</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m numerator \u001b[39m/\u001b[39m denominator\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\megan\\Documents\\Career\\MSDS\\DATA 515\\FinalProject\\data515\\lib\\site-packages\\torch\\_tensor.py:678\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/megan/Documents/Career/MSDS/DATA%20515/FinalProject/data515/lib/site-packages/torch/_tensor.py?line=675'>676</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m__array__, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    <a href='file:///c%3A/Users/megan/Documents/Career/MSDS/DATA%20515/FinalProject/data515/lib/site-packages/torch/_tensor.py?line=676'>677</a>\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/megan/Documents/Career/MSDS/DATA%20515/FinalProject/data515/lib/site-packages/torch/_tensor.py?line=677'>678</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m    <a href='file:///c%3A/Users/megan/Documents/Career/MSDS/DATA%20515/FinalProject/data515/lib/site-packages/torch/_tensor.py?line=678'>679</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/megan/Documents/Career/MSDS/DATA%20515/FinalProject/data515/lib/site-packages/torch/_tensor.py?line=679'>680</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "def print_closest_result(target, ranker):\n",
    "    closest_phrase_cos_sim = ranker.rank_on_similarity(target)[0]\n",
    "    print('------\\nTarget text phrase: ', target)\n",
    "    print('Most similar text phrase from corpus: ', closest_phrase_cos_sim[0])\n",
    "    print('Cosine similarity score: ', closest_phrase_cos_sim[1], '\\n------')\n",
    "\n",
    "#print text phrases and cosine similarity scores\n",
    "print_closest_result('massage', cosine_sim_ranker)\n",
    "print_closest_result('football', cosine_sim_ranker)\n",
    "print_closest_result('girls night out', cosine_sim_ranker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Using spell check before text similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['relaxin vacatin',\n",
       " 'girlz night outt',\n",
       " 'weddding party',\n",
       " 'bridal flowera',\n",
       " 'sokcer game',\n",
       " 'skate parkk']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example corpus with some spelling mistakes\n",
    "corpus_with_misspelling = input_data['misspelled_phrases'].values.tolist()\n",
    "corpus_with_misspelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_lg')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['relax vacation',\n",
       " 'girl night out',\n",
       " 'wedding party',\n",
       " 'bridal flower',\n",
       " 'soccer game',\n",
       " 'skate park']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textsimilarity import clean_text\n",
    "\n",
    "text_cleaner = clean_text.CleanText()\n",
    "\n",
    "#correct spelling errors\n",
    "spell_checked_phrases = []\n",
    "for phrase in corpus_with_misspelling:\n",
    "    corrected_phrase = text_cleaner.spelling_correction(phrase)\n",
    "    spell_checked_phrases.append(corrected_phrase)\n",
    "spell_checked_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify which model and corpus to use for comparison\n",
    "cosine_sim_ranker = rankers.CosineSimilarityRanker(\n",
    "                            bert_model, \n",
    "                            spell_checked_phrases\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "Target text phrase:  massage\n",
      "Most similar text phrase from corpus:  relax vacation\n",
      "Cosine similarity score:  0.9411255717277527 \n",
      "------\n",
      "------\n",
      "Target text phrase:  football\n",
      "Most similar text phrase from corpus:  soccer game\n",
      "Cosine similarity score:  0.9419365525245667 \n",
      "------\n",
      "------\n",
      "Target text phrase:  martini and chocolate\n",
      "Most similar text phrase from corpus:  girl night out\n",
      "Cosine similarity score:  0.9597087502479553 \n",
      "------\n"
     ]
    }
   ],
   "source": [
    "#print text phrases and cosine similarity scores\n",
    "print_closest_result('massage', cosine_sim_ranker)\n",
    "print_closest_result('football', cosine_sim_ranker)\n",
    "print_closest_result('martini and chocolate', cosine_sim_ranker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Using the profanity filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['relaxing vacation',\n",
       " 'girls night out',\n",
       " 'wedding party',\n",
       " 'bridal flowers',\n",
       " 'soccer game',\n",
       " 'skate park',\n",
       " 'go to hell']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example corpus containing a phrase with profanity\n",
    "profane_text_phrase = 'go to hell'\n",
    "comparison_corpus.append(profane_text_phrase)\n",
    "comparison_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['relaxing vacation',\n",
       " 'girls night out',\n",
       " 'wedding party',\n",
       " 'bridal flowers',\n",
       " 'soccer game',\n",
       " 'skate park']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove phrases that contain profanity\n",
    "for phrase in comparison_corpus:\n",
    "    is_profane = text_cleaner.determine_text_profanity(phrase)\n",
    "    if is_profane:\n",
    "        comparison_corpus.remove(phrase)\n",
    "comparison_corpus"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8c3adbe5a260b41ba9147af0d6966a33650f1ad814856e01b4b7c66ad6f6ef6e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('data515': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
